{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a11efca1-bebb-46f6-9d5e-f78dc28e7825",
   "metadata": {},
   "source": [
    "# M/EEG exam instructions\n",
    "- Assignment format: \n",
    "    - mandatory: a notebook with your answers \n",
    "    - optional: an additional document with your answers to the conceptual questions\n",
    "- Please send your assignment to M.Corsi's email address\n",
    "- Deadline: \n",
    "    - **Feb 22nd, 8AM.** Please not that an **extension will not be proposed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0af3406f-1d6f-43d2-a6e0-2dfdf0b1b46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "import mne\n",
    "from mne.datasets import eegbci\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.stats import permutation_cluster_1samp_test as pcluster_test\n",
    "from mne.time_frequency import tfr_multitaper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0765cb29-56ce-4c5e-8533-4b27e3301938",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Part 1 - Connectivity and Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be41298e-d10e-4a4b-830b-808eb4e3a74e",
   "metadata": {},
   "source": [
    "Here is an EEG dataset to load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61d2193e-97a8-4161-8896-9f08b31944b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /Users/marie-constance.corsi/Documents/GitHub/M2-MVA_MEEG_hands-on_materials/datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R06.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /Users/marie-constance.corsi/Documents/GitHub/M2-MVA_MEEG_hands-on_materials/datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R10.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /Users/marie-constance.corsi/Documents/GitHub/M2-MVA_MEEG_hands-on_materials/datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R14.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Used Annotations descriptions: ['T1', 'T2']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "45 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 45 events and 961 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    " \n",
    "#Define the parameters\n",
    "subject = 1  # use data from subject 1\n",
    "runs = [6, 10, 14]  # Motor imagery: hands vs feet\n",
    "\n",
    "# Extract raw data\n",
    "fnames = eegbci.load_data(subject=subject, runs=runs)\n",
    "raw = concatenate_raws([read_raw_edf(f, preload=True) for f in fnames])\n",
    "raw.rename_channels(lambda x: x.strip(\".\"))  # remove dots from channel names\n",
    "events, _ = mne.events_from_annotations(raw, event_id=dict(T1=2, T2=3))\n",
    "channel_names = raw.info['ch_names']\n",
    "\n",
    "# Extract trials between -1s and 4s\n",
    "tmin, tmax = -1, 4\n",
    "event_ids = dict(hands=2, feet=3)  # map event IDs to tasks\n",
    "epochs = mne.Epochs(\n",
    "    raw,\n",
    "    events,\n",
    "    event_ids,\n",
    "    tmin - 0.5,\n",
    "    tmax + 0.5,\n",
    "    baseline=None,\n",
    "    preload=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86733254-7769-47d0-a7cd-004b80ff9ed9",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "- For each condition:\n",
    "    - Compute and plot the connectivity matrices based on the estimation of the imaginary coherence averaged over the mu band and across the epochs. What does it say about potential changes between the tasks performed by the subject?\n",
    "    - Compute and plot the associated node strength averaged across the epochs. What does it say about potential changes between the tasks performed by the subject?\n",
    "\n",
    "- Here is the plot of the statistical difference between MI and Rest conditions obtained from imaginary coherence (left) and the results obtained with the node strength (right): What do you observe? Is it neurophysiologically meaningful?\n",
    "![Figure_ImCoh](./MI_Rest_ImCoh.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22149f58-5225-4608-831c-75a542d43db9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Part 2 - Features in BCI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee67d67-7f68-4277-a271-bb4b29fef966",
   "metadata": {},
   "source": [
    "Here is an EEG dataset to load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2762da8a-dca3-4dcf-a5d6-626a414bed16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /Users/marie-constance.corsi/Documents/GitHub/M2-MVA_MEEG_hands-on_materials/datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R06.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /Users/marie-constance.corsi/Documents/GitHub/M2-MVA_MEEG_hands-on_materials/datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R10.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /Users/marie-constance.corsi/Documents/GitHub/M2-MVA_MEEG_hands-on_materials/datasets/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R14.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Used Annotations descriptions: ['T1', 'T2']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "45 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 45 events and 961 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Applying baseline correction (mode: percent)\n",
      "Using a threshold of 1.724718\n",
      "stat_fun(H1): min=-4.067712 max=3.432081\n",
      "Running initial clustering\n",
      "Found 79 clusters\n",
      "Permuting 99 times...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccef3d73c5f46c0b8994fe7b4c2f41e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=99.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing cluster p-values\n",
      "Step-down-in-jumps iteration #1 found 1 cluster to exclude from subsequent iterations\n",
      "Permuting 99 times...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16d82946ece477aa8e765b05ca38636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=99.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing cluster p-values\n",
      "Step-down-in-jumps iteration #2 found 0 additional clusters to exclude from subsequent iterations\n",
      "Done.\n",
      "Using a threshold of -1.724718\n",
      "stat_fun(H1): min=-4.067712 max=3.432081\n",
      "Running initial clustering\n",
      "Found 96 clusters\n",
      "Permuting 99 times...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecc454db6854a3c88d98e5d4506627e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=99.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing cluster p-values\n",
      "Step-down-in-jumps iteration #1 found 0 clusters to exclude from subsequent iterations\n",
      "Done.\n",
      "No baseline correction applied\n",
      "Using a threshold of 1.724718\n",
      "stat_fun(H1): min=-8.523637 max=3.419585\n",
      "Running initial clustering\n",
      "Found 112 clusters\n",
      "Permuting 99 times...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2a4a6681964f4f833a062286a1230d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=99.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing cluster p-values\n",
      "Step-down-in-jumps iteration #1 found 0 clusters to exclude from subsequent iterations\n",
      "Done.\n",
      "Using a threshold of -1.724718\n",
      "stat_fun(H1): min=-8.523637 max=3.419585\n",
      "Running initial clustering\n",
      "Found 84 clusters\n",
      "Permuting 99 times...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8995333ccbca47c5ab944302ba918940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=99.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing cluster p-values\n",
      "Step-down-in-jumps iteration #1 found 1 cluster to exclude from subsequent iterations\n",
      "Permuting 99 times...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ca428abfa64d5694c1cc20347961b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=99.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing cluster p-values\n",
      "Step-down-in-jumps iteration #2 found 0 additional clusters to exclude from subsequent iterations\n",
      "Done.\n",
      "No baseline correction applied\n",
      "Using a threshold of 1.724718\n",
      "stat_fun(H1): min=-6.355431 max=5.751019\n",
      "Running initial clustering\n",
      "Found 150 clusters\n",
      "Permuting 99 times...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ee9d5209184812b8ed3747ce38515c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=99.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing cluster p-values\n",
      "Step-down-in-jumps iteration #1 found 1 cluster to exclude from subsequent iterations\n",
      "Permuting 99 times...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37491bc6bc146bcb003723e2438fac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=99.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing cluster p-values\n",
      "Step-down-in-jumps iteration #2 found 0 additional clusters to exclude from subsequent iterations\n",
      "Done.\n",
      "Using a threshold of -1.724718\n",
      "stat_fun(H1): min=-6.355431 max=5.751019\n",
      "Running initial clustering\n",
      "Found 77 clusters\n",
      "Permuting 99 times...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d49eb095188940739a98a2056cb80e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=99.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing cluster p-values\n",
      "Step-down-in-jumps iteration #1 found 0 clusters to exclude from subsequent iterations\n",
      "Done.\n",
      "No baseline correction applied\n",
      "Using a threshold of 1.713872\n",
      "stat_fun(H1): min=-5.676877 max=3.052649\n",
      "Running initial clustering\n",
      "Found 61 clusters\n",
      "Permuting 99 times...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c078b85f02d7420db63fc1b25dac943c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=99.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing cluster p-values\n",
      "Step-down-in-jumps iteration #1 found 0 clusters to exclude from subsequent iterations\n",
      "Done.\n",
      "Using a threshold of -1.713872\n",
      "stat_fun(H1): min=-5.676877 max=3.052649\n",
      "Running initial clustering\n",
      "Found 80 clusters\n",
      "Permuting 99 times...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f49eb64c15438ebea701e41360d38e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=99.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing cluster p-values\n",
      "Step-down-in-jumps iteration #1 found 0 clusters to exclude from subsequent iterations\n",
      "Done.\n",
      "No baseline correction applied\n",
      "Using a threshold of 1.713872\n",
      "stat_fun(H1): min=-3.687815 max=3.369164\n",
      "Running initial clustering\n",
      "Found 111 clusters\n",
      "Permuting 99 times...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85fc46b9209c46b692f9cd1e674efc08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=99.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing cluster p-values\n",
      "Step-down-in-jumps iteration #1 found 0 clusters to exclude from subsequent iterations\n",
      "Done.\n",
      "Using a threshold of -1.713872\n",
      "stat_fun(H1): min=-3.687815 max=3.369164\n",
      "Running initial clustering\n",
      "Found 105 clusters\n",
      "Permuting 99 times...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775c81a4366c44648a2d791ffb53fe8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=99.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing cluster p-values\n",
      "Step-down-in-jumps iteration #1 found 0 clusters to exclude from subsequent iterations\n",
      "Done.\n",
      "No baseline correction applied\n",
      "Using a threshold of 1.713872\n",
      "stat_fun(H1): min=-3.619173 max=3.517158\n",
      "Running initial clustering\n",
      "Found 133 clusters\n",
      "Permuting 99 times...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e29ecd899cf444c874b49a6a05cbb5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=99.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing cluster p-values\n",
      "Step-down-in-jumps iteration #1 found 1 cluster to exclude from subsequent iterations\n",
      "Permuting 99 times...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66bcbd2d5f10422eb98048b5a228cb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=99.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing cluster p-values\n",
      "Step-down-in-jumps iteration #2 found 0 additional clusters to exclude from subsequent iterations\n",
      "Done.\n",
      "Using a threshold of -1.713872\n",
      "stat_fun(H1): min=-3.619173 max=3.517158\n",
      "Running initial clustering\n",
      "Found 59 clusters\n",
      "Permuting 99 times...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbfd1c148be488992b2ce6a2f7d5325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=99.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing cluster p-values\n",
      "Step-down-in-jumps iteration #1 found 0 clusters to exclude from subsequent iterations\n",
      "Done.\n",
      "No baseline correction applied\n"
     ]
    }
   ],
   "source": [
    "#Define the parameters\n",
    "subject = 1  # use data from subject 1\n",
    "runs = [6, 10, 14]  # Motor imagery: hands vs feet\n",
    "\n",
    "# Extract raw data\n",
    "fnames = eegbci.load_data(subject=subject, runs=runs)\n",
    "raw = concatenate_raws([read_raw_edf(f, preload=True) for f in fnames])\n",
    "raw.rename_channels(lambda x: x.strip(\".\"))  # remove dots from channel names\n",
    "events, _ = mne.events_from_annotations(raw, event_id=dict(T1=2, T2=3))\n",
    "\n",
    "# Extract trials between -1s and 4s\n",
    "channelsOfInterest = \"T7\", \"C3\", 'O1' # to get the full list of channels you can type: raw.info['ch_names']\n",
    "tmin, tmax = -1, 4\n",
    "event_ids = dict(hands=2, feet=3)  # map event IDs to tasks\n",
    "epochs = mne.Epochs(\n",
    "    raw,\n",
    "    events,\n",
    "    event_ids,\n",
    "    tmin - 0.5,\n",
    "    tmax + 0.5,\n",
    "    picks=(channelsOfInterest),\n",
    "    baseline=None,\n",
    "    preload=True,\n",
    ")\n",
    "\n",
    "# Compare power spectra computed in each condition/channel \n",
    "freqs = np.arange(2, 45)\n",
    "vmin, vmax = -1, 1.5  # set min and max ERDS values in plot\n",
    "baseline = (-1, 0)  # baseline interval (in s)\n",
    "cnorm = TwoSlopeNorm(vmin=vmin, vcenter=0, vmax=vmax)  # min, center & max ERDS\n",
    "\n",
    "kwargs = dict(\n",
    "    n_permutations=100, step_down_p=0.05, seed=1, buffer_size=None, out_type=\"mask\"\n",
    ")  # for cluster test\n",
    "\n",
    "# Time-Frequency decomposition\n",
    "tfr = tfr_multitaper(\n",
    "    epochs,\n",
    "    freqs=freqs,\n",
    "    n_cycles=freqs,\n",
    "    use_fft=True,\n",
    "    return_itc=False,\n",
    "    average=False,\n",
    "    decim=2,\n",
    ")\n",
    "tfr.crop(tmin, tmax).apply_baseline(baseline, mode=\"percent\")\n",
    "\n",
    "nb_channels = len(channelsOfInterest)\n",
    "for event in event_ids:\n",
    "    # select desired epochs for visualization\n",
    "    tfr_ev = tfr[event]\n",
    "    fig, axes = plt.subplots(\n",
    "        1, 4, figsize=(12, 4), gridspec_kw={\"width_ratios\": [10, 10, 10, 1]}\n",
    "    )\n",
    "    for ch, ax in enumerate(axes[:-1]):  # for each channel\n",
    "        # positive clusters\n",
    "        _, c1, p1, _ = pcluster_test(tfr_ev.data[:, ch], tail=1, **kwargs)\n",
    "        # negative clusters\n",
    "        _, c2, p2, _ = pcluster_test(tfr_ev.data[:, ch], tail=-1, **kwargs)\n",
    "\n",
    "        # note that we keep clusters with p <= 0.05 from the combined clusters\n",
    "        # of two independent tests; in this example, we do not correct for\n",
    "        # these two comparisons\n",
    "        c = np.stack(c1 + c2, axis=2)  # combined clusters\n",
    "        p = np.concatenate((p1, p2))  # combined p-values\n",
    "        mask = c[..., p <= 0.05].any(axis=-1)\n",
    "\n",
    "        # plot TFR (ERDS map with masking)\n",
    "        tfr_ev.average().plot(\n",
    "            [ch],\n",
    "            cmap=\"RdBu\",\n",
    "            cnorm=cnorm,\n",
    "            axes=ax,\n",
    "            colorbar=False,\n",
    "            show=False,\n",
    "            mask=mask,\n",
    "            mask_style=\"mask\",\n",
    "        )\n",
    "\n",
    "        ax.set_title(epochs.ch_names[ch], fontsize=10)\n",
    "        ax.axvline(0, linewidth=1, color=\"black\", linestyle=\":\")  # event\n",
    "        if ch != 0:\n",
    "            ax.set_ylabel(\"\")\n",
    "            ax.set_yticklabels(\"\")\n",
    "    fig.colorbar(axes[0].images[-1], cax=axes[-1]).ax.set_yscale(\"linear\")\n",
    "    fig.suptitle(f\"ERDS ({event})\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc159f64-b422-4c76-9ee1-562236006fcf",
   "metadata": {},
   "source": [
    "## Questions: \n",
    "- Please describe the observations you can make from the maps. Are there neurophysiologically relevant/meaningful?\n",
    "- To what extent such observations are informative of BCI performance?\n",
    "- If you were the experimenter, based on the previous observations, which (electrode(s); frequency bin(s)) couples would you pick to extract the features? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c872d66e-039c-476d-b659-f176f3b3170f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Part 3 - Machine Learning & BCI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c76632-92e0-4d9c-8d92-11f9744507c6",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "Here is a publicly available [BCI dataset](http://moabb.neurotechx.com/docs/generated/moabb.datasets.BNCI2014_001.html#moabb.datasets.BNCI2014_001) (cf below to load the data and to get information regarding the experimental information). In the following lines of code we defined two classification pipelines (CSP+LDA: Common Spatial Patterns + LDA, RG+LR:Riemannian Geometry + Logistic Regression), and we plotted their performances from a dataset composed of 2 subjects.\n",
    "\n",
    "## Questions\n",
    "- What observations can be made from the plots? \n",
    "- Instead of those implemented here, what framework would you propose to extract, select, and classify the features? Why? How would you assess the performance of your approach?\n",
    "\n",
    "## BONUS\n",
    "- Implement below your framework and compare it to the other pipelines (namely RG+LR and CSP+LDA). \n",
    "- What are your conclusions? Do you have some suggestion(s) to improve the performance of your framework?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9199147d-56ce-480e-a0df-47dd7d8dafa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 12:16:47,670 INFO MainThread moabb.evaluations.base Processing dataset: 001-2014\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "from mne.decoding import CSP\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import moabb\n",
    "from moabb.datasets import BNCI2014001 # note: if you use MOABB>1.1, please change it as BNCI2014_001\n",
    "from moabb.evaluations import WithinSessionEvaluation\n",
    "from moabb.paradigms import LeftRightImagery\n",
    "\n",
    "moabb.set_log_level(\"info\")\n",
    "mne.set_log_level(\"CRITICAL\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "###### PIPELINES TO BE COMPARED (do not modify it!) ######\n",
    "# baseline pipeline to be used to make the comparison, please complete the following line with your framework\n",
    "pipelines = {}\n",
    "pipelines[\"CSP+LDA\"] = make_pipeline(CSP(n_components=8), LDA())\n",
    "pipelines[\"RG+LR\"] = make_pipeline(\n",
    "    Covariances(), TangentSpace(), LogisticRegression(solver=\"lbfgs\")\n",
    ")\n",
    "### BONUS - implementation of your framework ######\n",
    "#pipelines[\"MyPipeline\"] =\n",
    "\n",
    "\n",
    "###### DATASET TO BE USED (do not modify it!) - downloading it the first time can take some time ######\n",
    "dataset = BNCI2014001() # if you are using a more recent version of moabb please change it as BNCI2014_001\n",
    "subj = [1, 2]\n",
    "dataset.subject_list = subj\n",
    "\n",
    "\n",
    "###### DEFINITION OF THE PARADIGM & EVALUATION (do not modify it!) ######\n",
    "paradigm = LeftRightImagery()\n",
    "evaluation = WithinSessionEvaluation(\n",
    "    paradigm=paradigm, datasets=dataset, overwrite=False\n",
    ")\n",
    "results = evaluation.process(pipelines)\n",
    "#print(results.head()) # if you want to look at it...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "983471db-f9a2-49aa-9f7c-9012b0d0fe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### SCRIPT TO PLOT THE RESULTS (do not modify it unless you want to add your framework!) #########\n",
    "\n",
    "# Plot the global distribution of the performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=[8, 4], sharey=True)\n",
    "\n",
    "sns.stripplot(\n",
    "    data=results,\n",
    "    y=\"score\",\n",
    "    x=\"pipeline\",\n",
    "    ax=axes[0],\n",
    "    jitter=True,\n",
    "    alpha=0.5,\n",
    "    zorder=1,\n",
    "    palette=\"rocket\",\n",
    ")\n",
    "sns.pointplot(data=results, y=\"score\", x=\"pipeline\", ax=axes[0], palette=\"rocket\")\n",
    "\n",
    "axes[0].set_ylabel(\"ROC AUC\")\n",
    "axes[0].set_ylim(0.5, 1)\n",
    "\n",
    "paired = results.pivot_table(\n",
    "    values=\"score\", columns=\"pipeline\", index=[\"subject\", \"session\"]\n",
    ")\n",
    "paired = paired.reset_index()\n",
    "\n",
    "sns.regplot(data=paired, y=\"RG+LR\", x=\"CSP+LDA\", ax=axes[1], fit_reg=False)\n",
    "axes[1].plot([0, 1], [0, 1], ls=\"--\", c=\"k\")\n",
    "axes[1].set_xlim(0.5, 1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot the individual distribution of the performance\n",
    "g = sns.catplot(\n",
    "    kind=\"bar\",\n",
    "    x=\"score\",\n",
    "    y=\"subject\",\n",
    "    hue=\"pipeline\",\n",
    "    col=\"dataset\",\n",
    "    height=12,\n",
    "    aspect=0.5,\n",
    "    data=results,\n",
    "    orient=\"h\",\n",
    "    palette=\"rocket\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155fb091-bb44-421d-8e8f-8fe9c6f2991c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Part 4 - Experimental considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8e0058-7ee5-4c95-8fea-25f081e239c2",
   "metadata": {},
   "source": [
    "You plan to launch a new protocol based on EEG acquisitions:\n",
    "- What are the two main types of artifacts you may observe? Please indicate one example for each of them.\n",
    "- What are the main steps that compose an EEG processing pipeline?\n",
    "\n",
    "Now you are conducting and experimental protocol in BCI. It consists in 5 sessions of right hand motor imagery vs rest. After the fourth session training sessions subject Y still shows a global performance of 60%. \n",
    "At each session:\n",
    "- You instructed the subject to perform a right motor imagery when the visual target was up and to remain at rest when the visual target was down.\n",
    "- You always selected the same features (power spectra in CP3 at 10Hz & 14Hz, and in C3 at 12Hz & 16Hz).\n",
    "\n",
    "Based on these elements, what would be your suggestions to help the subject Y improving their performance at session 5?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
